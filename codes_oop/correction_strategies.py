from abc import ABC, abstractmethod
from typing import List, TYPE_CHECKING
import numpy as np

if TYPE_CHECKING:
    from llm_client import LLMClient
    from metrics import MetricsCalculator

class CorrectionStrategy(ABC):
    """
    Abstract base class for ASR error correction strategies.
    """

    @abstractmethod
    async def correct(self, hypotheses: List[str], llm_client: 'LLMClient', model: str, generation_config: dict) -> str:
        """
        Abstract method to perform error correction on ASR hypotheses.

        Args:
            hypotheses (List[str]): A list of ASR hypotheses.
            llm_client (LLMClient): An instance of LLMClient to interact with the language model.
            model (str): The name of the language model to use.
            generation_config (dict): Generation configuration for the language model.

        Returns:
            str: The corrected or selected transcript.
        """
        pass

class OneShotUnconstrainedCorrection(CorrectionStrategy):
    """
    Generates a corrected transcription using a language model without constraints and in 1-shot setting.
    """
    async def correct(self, hypotheses: List[str], llm_client: 'LLMClient', model: str, generation_config: dict) -> str:

        prompt = ("""Input: Perform error correction based on the top 5 outputs generated by an Automatic Speech Recognition (ASR) system.                      The ASR hypotheses are listed in order of their ASR posterior score. You need to provide the corrected ASR hypothesis                        directly without any explanations. Here is seven in-context examples:\n\n
                     Example 1:\n
                     <hypothesis1> see stongers were executed for these crimes and manures devoted to other islands </hypothesis1>\n
                     <hypothesis2> the stungers were executed for this crime and maneuvers devoted to other islands </hypothesis2>\n
                     <hypothesis3> the stungers were executed for this crime and many were deported to other islands </hypothesis3>\n
                     <hypothesis4> the strongest were executed for the crime and maneuvers deported to other islands </hypothesis4>\n
                     <hypothesis5> the stungers were executed for these crimes and maneuvers devoted to other islands </hypothesis5>\n\n
                     
                     Your output: six tongans were executed for this crime and many were deported to other islands\n\n
                     
                     
                     
                     Example 2:\n
                     <hypothesis1> the hamlet of whitewell likes to the west </hypothesis1>\n
                     <hypothesis2> the hamlet of white will lights to the west </hypothesis2>\n
                     <hypothesis3> the hamlet of whitewell lies to the west</hypothesis3>\n
                     <hypothesis4> the hamlet of whitewill lies to the west </hypothesis4>\n
                     <hypothesis5> the hamlet of whiteville likes to the west </hypothesis5>\n\n
                     
                     Your output: the hamlet of whitewell lies to the west\n\n
                     
                     
                     
                     
                     Example 3:\n
                     <hypothesis1> conway was farmed and disguised as conway </hypothesis1>\n
                     <hypothesis2> konui was formed and disguised as konui </hypothesis2>\n
                     <hypothesis3> conroy was formed and disguised as conway </hypothesis3>\n
                     <hypothesis4> conway was formed and disguised as conway </hypothesis4>\n
                     <hypothesis5> connolly was formed and disguised as conway </hypothesis5>\n\n
                     
                     Your output: conwy was formerly anglicized as conway \n\n
                     
                     
                     
                     
                      Example 4:\n
                     <hypothesis1> due to space limitations as an extremely narrow platform </hypothesis1>\n
                     <hypothesis2> due to space limitation as an extremely narrow platform </hypothesis2>\n
                     <hypothesis3> due to space limitation as an extremely narrow platform </hypothesis3>\n
                     <hypothesis4> due to space limitations as an extremely narrow platform </hypothesis4>\n
                     <hypothesis5> due to space limitations as an extremely narrow platform </hypothesis5>\n\n
                     
                     Your output: due to space limitations it has an extremely narrow platform \n\n
                     
                     
                     
                                          
                     Example 5:\n
                     <hypothesis1> the band continues to tune nationally </hypothesis1>\n
                     <hypothesis2> the band continues to tour nationally </hypothesis2>\n
                     <hypothesis3> the band continues to do it nationally </hypothesis3>\n
                     <hypothesis4> the band continues to tour nationally </hypothesis4>\n
                     <hypothesis5> the band continues to do it nationally </hypothesis5>\n\n
                     
                     Your output: the band continues to tour nationally \n\n
                     
                     
                     Example 6:\n
                     <hypothesis1> around holdcroft requires a lot more skill to keep upright </hypothesis1>\n
                     <hypothesis2> around holdcroft requires a lot more skill to keep upright </hypothesis2>\n
                     <hypothesis3> around hold croft requires a lot more skill to keep upright </hypothesis3>\n
                     <hypothesis4> a roundhold craft requires a lot more skill to keep upright </hypothesis4>\n
                     <hypothesis5> around hold craft requires a lot more skill to keep upright </hypothesis5>\n\n
                     
                     Your output: a round hulled craft requires a lot more skill to keep upright \n\n
                     
                     
                     Example 7:\n
                     <hypothesis1> tom the montana is a collective term for the appland varieties e g </hypothesis1>\n
                     <hypothesis2> tom the monten is a collective term for the upland varieties e g </hypothesis2>\n
                     <hypothesis3> tom the monten is a collective term for the appland varieties e g </hypothesis3>\n
                     <hypothesis4> tom the monten is a collective term for the appland varieties e g </hypothesis4>\n
                     <hypothesis5> tom the montana is a collective term for the appland varieties e g </hypothesis5>\n\n
                     
                     Your output: tomme de montagne is a collective term for the upland varieties e g \n\n
                     
                     Feel free to refer to these examples, and also do not add any explanation or other words. Please start:\n""")
                  
                 
        
        for idx, hypothesis in enumerate(hypotheses):
            prompt += f"<hypothesis{idx}>{hypothesis}</hypothesis{idx}>\n"
        prompt += "\n your output:"
        messages = llm_client.construct_input_prompt(prompt)
        return await llm_client.get_prediction(model, messages, generation_config)


class OneShotClosestCorrection(CorrectionStrategy):
    """
    Selects the hypothesis closest to an unconstrained correction output based on Levenshtein distance.
    """
    def __init__(self, metrics_calculator: 'MetricsCalculator'):
        """
        Initialize ZeroShotClosestCorrection with a MetricsCalculator instance.

        Args:
            metrics_calculator (MetricsCalculator): Instance of MetricsCalculator to compute distances.
        """
        self.metrics_calculator = metrics_calculator

    async def correct(self, hypotheses: List[str], llm_client: 'LLMClient', model: str, generation_config: dict) -> str:
        """
        Selects the hypothesis closest to an unconstrained correction output within 1-shot setting. """
                  
        unconstrained_result = await OneShotUnconstrainedCorrection().correct(hypotheses, llm_client, model, generation_config)
        distances = [self.metrics_calculator.compute_levenshtein_distance(unconstrained_result, hyp) for hyp in hypotheses]
        best_idx = np.argmin(distances)
        return hypotheses[best_idx]

class OracleHypothesisSelection(CorrectionStrategy):
    """
    Selects the hypothesis with the lowest WER compared to the reference (oracle baseline).
    """
    def __init__(self, metrics_calculator: 'MetricsCalculator'):
        """
        Initialize OracleHypothesisSelection with a MetricsCalculator instance.

        Args:
            metrics_calculator (MetricsCalculator): Instance of MetricsCalculator to compute WER.
        """
        self.metrics_calculator = metrics_calculator

    async def correct(self, hypotheses: List[str], llm_client: 'LLMClient', model: str, generation_config: dict, reference: str = None) -> str:
        """
        Selects the hypothesis with the lowest WER compared to the reference.

        Args:
            hypotheses (List[str]): A list of ASR hypotheses.
            llm_client (LLMClient): An instance of LLMClient (not used in this strategy).
            model (str): The name of the language model (not used in this strategy).
            generation_config (dict): Generation configuration (not used in this strategy).
            reference (str, optional): The reference transcript. Must be provided for Oracle selection. Defaults to None.

        Returns:
            str: The oracle hypothesis.
        """
        if reference is None:
            raise ValueError("Reference transcript is required for Oracle Hypothesis Selection.")
        wers = [self.metrics_calculator.compute_wer(reference, hyp) for hyp in hypotheses]
        best_idx = np.argmin(wers)
        return hypotheses[best_idx]

class Top1HypothesisSelection(CorrectionStrategy):
    """
    Returns the first hypothesis from the list (top 1 baseline).
    """
    async def correct(self, hypotheses: List[str], llm_client: 'LLMClient', model: str, generation_config: dict) -> str:
        """
        Returns the first hypothesis from the list.

        Args:
            hypotheses (List[str]): A list of ASR hypotheses.
            llm_client (LLMClient): An instance of LLMClient (not used in this strategy).
            model (str): The name of the language model (not used in this strategy).
            generation_config (dict): Generation configuration (not used in this strategy).

        Returns:
            str: The top 1 hypothesis.
        """
        return hypotheses[0]

# # Placeholder for future strategies (you can implement them similarly)
# class ZeroShotLatticeCorrection(CorrectionStrategy):
#     async def correct(self, hypotheses: List[str], llm_client: 'LLMClient', model: str, generation_config: dict) -> str:
#         pass # TO DO LATER

# class CoTTaskActivatingCorrection(CorrectionStrategy):
#     async def correct(self, hypotheses: List[str], llm_client: 'LLMClient', model: str, generation_config: dict) -> str:
#         pass # TO DO LATER