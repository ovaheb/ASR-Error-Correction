{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "enhanced-sector",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "architectural-investing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /h/omidv/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /h/omidv/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from codes.evaluation import *\n",
    "from codes.configs import *\n",
    "load_dotenv() # Load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nonprofit-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/fs01/home/omidv/ASR-Error-Correction/data/test_cv.json\")\n",
    "cv_results_path = \"/fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\"\n",
    "cv_dataset = Dataset.from_pandas(df)\n",
    "df = pd.read_json(\"/fs01/home/omidv/ASR-Error-Correction/data/test_lrs2.json\")\n",
    "lrs_results_path = \"/fs01/home/omidv/ASR-Error-Correction/results/test_lrs2.json\"\n",
    "lrs_dataset = Dataset.from_pandas(df)\n",
    "df = pd.read_json(\"/fs01/home/omidv/ASR-Error-Correction/data/test_chime4.json\")\n",
    "chime_results_path = \"/fs01/home/omidv/ASR-Error-Correction/results/test_chime4.json\"\n",
    "chime_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-utility",
   "metadata": {},
   "source": [
    "## GPT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fourth-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = openai.AsyncOpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "political-precipitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm an AI language model created by OpenAI, designed to assist and provide information on a wide range of topics. I can help with questions, generate text, support creative writing, and provide explanations in various fields. If there's anything specific you'd like to know or discuss, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "await check_availability(client, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exclusive-overhead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 530\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 243\n",
      "sentence 1\n",
      "REF: the saint george leagues club is located nearby on  princes highway\n",
      "HYP: the    st george leagues club is located nearby on princess highway\n",
      "             S                                                 S        \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1447\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.143, 'METEOR': 0.884, 'BERT Precision': 0.815, 'BERT Recall': 0.832, 'BERT F1': 0.823}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct1, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "signal-relief",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 184\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 773\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1401\n",
      "sentence 1\n",
      "REF: they have to develop the software and hardware\n",
      "HYP: they have to develop the software  in hardware\n",
      "                                         S         \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.137, 'METEOR': 0.882, 'BERT Precision': 0.81, 'BERT Recall': 0.824, 'BERT F1': 0.817}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct1_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pending-burst",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 320\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 806\n",
      "sentence 1\n",
      "REF: ** **** *** vincennes in uraga channel at the mouth to tokyo bay\n",
      "HYP: we will see      this in oraga channel at the mouth to tokyo bay\n",
      "      I    I   I         S        S                                  \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1331\n",
      "sentence 1\n",
      "REF: it is effective against         gram positive and         gram negative bacteria yeast and fungi\n",
      "HYP: it is effective against grampositive ******** and gramnegative ******** bacteria yeast and fungi\n",
      "                                        S        D                S        D                         \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.157, 'METEOR': 0.877, 'BERT Precision': 0.811, 'BERT Recall': 0.828, 'BERT F1': 0.82}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct2, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "established-incidence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1589\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1908\n",
      "sentence 1\n",
      "REF: fuel was carried in two tanks in the upper wings\n",
      "HYP: fall was carried in two times in the upper wings\n",
      "        S                        S                   \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 277\n",
      "sentence 1\n",
      "REF: others found    work       as peddlers jewelers launderers hebrew tutors and even shopkeepers\n",
      "HYP:  other found workers pedalers ******** jewelers  launchers hebrew tutors and even shopkeepers\n",
      "          S             S        S        D                   S                                   \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.138, 'METEOR': 0.882, 'BERT Precision': 0.81, 'BERT Recall': 0.824, 'BERT F1': 0.817}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct2_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "casual-inspection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1472\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 364\n",
      "sentence 1\n",
      "REF: as a result ***** poglavnik is sometimes translated as fuhrer in english language sources\n",
      "HYP: as a result hogue   labniki is sometimes translated as  fewer in english language sources\n",
      "                     I         S                                 S                            \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 71\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.156, 'METEOR': 0.878, 'BERT Precision': 0.811, 'BERT Recall': 0.828, 'BERT F1': 0.82}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct3, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "convenient-cleaners",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1736\n",
      "sentence 1\n",
      "REF: ** its county seat is blue earth\n",
      "HYP: it  is county seed is blue earth\n",
      "      I   S           S              \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 407\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 864\n",
      "sentence 1\n",
      "REF: queen elena granted ******* anatoly durov  jun\n",
      "HYP: queen elena granted anatoli    duro    of june\n",
      "                               I       S     S    S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.138, 'METEOR': 0.881, 'BERT Precision': 0.81, 'BERT Recall': 0.825, 'BERT F1': 0.818}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct3_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "broadband-disney",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 915\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1987\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 278\n",
      "sentence 1\n",
      "REF: he hails from the lau islands\n",
      "HYP: he hails from the lao islands\n",
      "                         S        \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.151, 'METEOR': 0.881, 'BERT Precision': 0.813, 'BERT Recall': 0.83, 'BERT F1': 0.821}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct4, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dominican-advocate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1760\n",
      "sentence 1\n",
      "REF: the recommendation was turned down initially but *** cooper key persevered\n",
      "HYP: the recommendation was turned down initially but cup     of tea  preserved\n",
      "                                                        I      S   S          S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 677\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1315\n",
      "sentence 1\n",
      "REF: i would like to stress **** nothing in ethiopia will change\n",
      "HYP: i would like to stress that nothing in ethiopia will change\n",
      "                               I                                \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.137, 'METEOR': 0.882, 'BERT Precision': 0.811, 'BERT Recall': 0.826, 'BERT F1': 0.818}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct4_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "developed-indie",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 817\n",
      "sentence 1\n",
      "REF: as the  terms progress the restrictions are relaxed\n",
      "HYP: as the storms progress the restrictions are relaxed\n",
      "                 S                                      \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 72\n",
      "sentence 1\n",
      "REF:  leo mcleay was born in sydney and was a telephone technician before entering politics\n",
      "HYP: liam mcleay was born in sydney and was a telephone technician before entering politics\n",
      "        S                                                                                  \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1122\n",
      "sentence 1\n",
      "REF: thereafter it became part of the kingdom of hungary within        austria hungary\n",
      "HYP: thereafter it became part of the kingdom of hungary within austriahungary *******\n",
      "                                                                             S       D\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.223, 'METEOR': 0.841, 'BERT Precision': 0.777, 'BERT Recall': 0.785, 'BERT F1': 0.781}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct5, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fluid-northern",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1494\n",
      "sentence 1\n",
      "REF: she is the middle of three daughters born to douglas and   angela chalke\n",
      "HYP: she is the middle of three daughters born to douglas and angelina  quack\n",
      "                                                                     S      S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 407\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1571\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.135, 'METEOR': 0.884, 'BERT Precision': 0.813, 'BERT Recall': 0.826, 'BERT F1': 0.819}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct5_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acoustic-greensboro",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 873\n",
      "sentence 1\n",
      "REF: the controversy led to    drawn out protests between parents and authorities\n",
      "HYP: the controversy led to drawnout *** protests between parents and authorities\n",
      "                                   S   D                                         \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1416\n",
      "sentence 1\n",
      "REF: this work is commonly referred to as     de orbe for short\n",
      "HYP: this work is commonly referred to as doctor **** for short\n",
      "                                               S    D          \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 142\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.157, 'METEOR': 0.876, 'BERT Precision': 0.809, 'BERT Recall': 0.824, 'BERT F1': 0.816}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct6, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acting-homeless",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 258\n",
      "sentence 1\n",
      "REF: there are still three *** neonazis in the  town is parliament\n",
      "HYP: there are still three new    nazis in the towns ** parliament\n",
      "                             I        S            S  D           \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1145\n",
      "sentence 1\n",
      "REF: this  cadre of educators went out into remote communities to teach rural blacks\n",
      "HYP:  the skater of educators went out into remote communities to teach rural blacks\n",
      "        S      S                                                                    \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 793\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.14, 'METEOR': 0.88, 'BERT Precision': 0.808, 'BERT Recall': 0.822, 'BERT F1': 0.815}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct6_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "french-acceptance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1394\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 360\n",
      "sentence 1\n",
      "REF: the head is dark gray and the blackish tail is tipped with pale gray brown\n",
      "HYP: the  hat is dark gray and the blackish tail is tipped with pale gray brown\n",
      "            S                                                                  \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 31\n",
      "sentence 1\n",
      "REF: steller has participated in the  alaska mock trial competition for a number of years\n",
      "HYP: stellar has participated in the alaskan mock trial competition for a number of years\n",
      "           S                               S                                             \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.141, 'METEOR': 0.885, 'BERT Precision': 0.815, 'BERT Recall': 0.834, 'BERT F1': 0.824}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powerful-anger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 321\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1526\n",
      "sentence 1\n",
      "REF: snorri sturluson writing a century later said that konghelle never completely recovered\n",
      "HYP:  stori sturluson writing a century later said that    gornal never completely recovered\n",
      "          S                                                     S                           \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 273\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.138, 'METEOR': 0.882, 'BERT Precision': 0.81, 'BERT Recall': 0.824, 'BERT F1': 0.817}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "swiss-interval",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 894\n",
      "sentence 1\n",
      "REF: he has published works ** under several other names including grandma and i cactus\n",
      "HYP: he has published works on   the several other names including   raman and i cactus\n",
      "                             I     S                                     S             \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 546\n",
      "sentence 1\n",
      "REF: caramon wears a winged helmet and his face bears a look of grim determination\n",
      "HYP: karaman wears a winged helmet and his face bears a look of grim determination\n",
      "           S                                                                      \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1759\n",
      "sentence 1\n",
      "REF: **** ** kingscliff is a beach community offering a variety of holiday accommodations\n",
      "HYP: king is       clif is a beach community offering a variety of holiday accommodations\n",
      "        I  I          S                                                                  \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.16, 'METEOR': 0.865, 'BERT Precision': 0.783, 'BERT Recall': 0.795, 'BERT F1': 0.789}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct8, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "lesbian-courage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1814\n",
      "sentence 1\n",
      "REF: blind with rage he darted in\n",
      "HYP: blind with rage he dotted in\n",
      "                             S   \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 200\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 921\n",
      "sentence 1\n",
      "REF: there are many temples mosques churches **** guruduwaras\n",
      "HYP: there are many temples mosques churches rudu       waras\n",
      "                                                I           S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.158, 'METEOR': 0.865, 'BERT Precision': 0.784, 'BERT Recall': 0.795, 'BERT F1': 0.79}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct8_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "related-mozambique",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1170\n",
      "sentence 1\n",
      "REF: ***** prescott  is novel the man on     a donkey\n",
      "HYP: these    codes now   are the men on enter    key\n",
      "         I        S   S     S       S        S      S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 934\n",
      "sentence 1\n",
      "REF: her right hand holds a patera which she is tipping onto a cylindrical altar\n",
      "HYP: her right hand holds a petara which she is tipping onto a cylindrical altar\n",
      "                                 S                                              \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1519\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.163, 'METEOR': 0.862, 'BERT Precision': 0.779, 'BERT Recall': 0.791, 'BERT F1': 0.785}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct9, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "human-garage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1933\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1981\n",
      "sentence 1\n",
      "REF: all songs were written by  ian anderson and recorded at his home studio\n",
      "HYP: all songs were written by iyan anderson and recorded at his home studio\n",
      "                                  S                                         \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1750\n",
      "sentence 1\n",
      "REF: his stripes are displayed in private homes public places and museums worldwide\n",
      "HYP: his   types are displayed in private homes public places and museums worldwide\n",
      "               S                                                                   \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.163, 'METEOR': 0.861, 'BERT Precision': 0.78, 'BERT Recall': 0.792, 'BERT F1': 0.786}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct9_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "young-threshold",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 487\n",
      "sentence 1\n",
      "REF: ** its surfing **** is world renowned but the difficulty in reaching the island keeps most away\n",
      "HYP: it  is surfing that is world renowned but the difficulty in reaching the island keeps most away\n",
      "      I   S            I                                                                            \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 264\n",
      "sentence 1\n",
      "REF: *** ** morris later recovered by winning all  star third in the tournament\n",
      "HYP: now it     is later  recorded by winning all stars third in the tournament\n",
      "       I  I      S               S                    S                        \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1678\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.141, 'METEOR': 0.884, 'BERT Precision': 0.812, 'BERT Recall': 0.83, 'BERT F1': 0.821}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7a, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "descending-radical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1784\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1675\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 279\n",
      "sentence 1\n",
      "REF: whatever his name he is a trickster a rebel and a wife beater\n",
      "HYP: whatever his name he is a trickster a rebel and a wife beetle\n",
      "                                                                 S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.138, 'METEOR': 0.881, 'BERT Precision': 0.809, 'BERT Recall': 0.824, 'BERT F1': 0.816}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7a_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "measured-booth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 258\n",
      "sentence 1\n",
      "REF: there are still three *** neonazis in the  town is parliament\n",
      "HYP: there are still three new    nazis in the towns ** parliament\n",
      "                             I        S            S  D           \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1554\n",
      "sentence 1\n",
      "REF:   a person flying through the air on a bicycle\n",
      "HYP: the person flying through the air on a bicycle\n",
      "       S                                           \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 688\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.144, 'METEOR': 0.883, 'BERT Precision': 0.813, 'BERT Recall': 0.831, 'BERT F1': 0.822}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7b, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "emotional-reduction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1672\n",
      "sentence 1\n",
      "REF: **** postwar beech stocks are more affected than the older walnut ones\n",
      "HYP: post     war beach stocks are more affected than the older walnut ones\n",
      "        I       S     S                                                    \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 842\n",
      "sentence 1\n",
      "REF: he was a friend and patron of abraham cowley and sir william davenant\n",
      "HYP: he was a friend and patron of abraham   coli and sir william davenant\n",
      "                                                S                         \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1339\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.138, 'METEOR': 0.881, 'BERT Precision': 0.809, 'BERT Recall': 0.824, 'BERT F1': 0.817}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7b_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proof-capital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1532\n",
      "sentence 1\n",
      "REF: the city is chief of police is roger thompson\n",
      "HYP: the city is shape of police is  roja thompson\n",
      "                     S                  S         \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 368\n",
      "sentence 1\n",
      "REF: emperor an executed wang and bing and exiled their families\n",
      "HYP:     and ** executed wang and bang and exiled their families\n",
      "           S  D                      S                          \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1348\n",
      "sentence 1\n",
      "REF: she appeared in the play on the shore of the  wide world\n",
      "HYP: she appeared in the play on the shore of the white  girl\n",
      "                                                      S     S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.14, 'METEOR': 0.885, 'BERT Precision': 0.814, 'BERT Recall': 0.832, 'BERT F1': 0.823}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7c, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "delayed-belize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1518\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1796\n",
      "sentence 1\n",
      "REF:   they were anti republican anti democratic and preached government on high by    a marked noble elite\n",
      "HYP: though   an anti republican anti democratic and   preach government on high by mark ****** noble elite\n",
      "          S    S                                            S                          S      D            \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 659\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.138, 'METEOR': 0.882, 'BERT Precision': 0.809, 'BERT Recall': 0.823, 'BERT F1': 0.816}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7c_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "outstanding-packaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 40 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 726\n",
      "sentence 1\n",
      "REF: the company which runs retail automotive stores told shearson lehman brothers its financial adviser to terminate discussions to sell the firm\n",
      "HYP: the company which runs retail automotive stores told shearson lehman brothers its financial advisor to terminate discussions to sell the firm\n",
      "                                                                                                       S                                          \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1115\n",
      "sentence 1\n",
      "REF: he also said that the company for the first time was developing drugs specifically for the           over the counter consumer     health care market\n",
      "HYP: he also said that the company for the first time was developing drugs specifically for the overthecounter *** ******* consumer healthcare **** market\n",
      "                                                                                                             S   D       D                   S    D       \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 937\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_chime4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.129, 'METEOR': 0.916, 'BERT Precision': 0.855, 'BERT Recall': 0.856, 'BERT F1': 0.856}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(chime_dataset, model, client, zero_shot_instruct7a, chime_generation_config, chime_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "historical-quebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 40 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1240\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1044\n",
      "sentence 1\n",
      "REF: two years ago    b a s f made three separate acquisitions in the  u s\n",
      "HYP: two years ago basf * * * made three separate acquisitions in the us *\n",
      "                      S D D D                                          S D\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 884\n",
      "sentence 1\n",
      "REF: the company declined to identify the bidders but said it received offers in the high forty dollars per share\n",
      "HYP: the company declined to identify the bidders but said it received offers in the high forty ******* per share\n",
      "                                                                                                      D          \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_chime4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.107, 'METEOR': 0.923, 'BERT Precision': 0.883, 'BERT Recall': 0.878, 'BERT F1': 0.881}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(chime_dataset, model, client, zero_shot_instruct7a_closest, chime_generation_config, chime_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "divine-institute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 40 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 524\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 69\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 75\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_chime4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.135, 'METEOR': 0.913, 'BERT Precision': 0.851, 'BERT Recall': 0.854, 'BERT F1': 0.853}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(chime_dataset, model, client, zero_shot_instruct7b, chime_generation_config, chime_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "developing-personal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 40 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1176\n",
      "sentence 1\n",
      "REF: the issue is rated single a by moody is and single a minus by s and p\n",
      "HYP: the issue is rated single a by moody is and single a minus by s *** p\n",
      "                                                                       D  \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 738\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 219\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_chime4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.107, 'METEOR': 0.924, 'BERT Precision': 0.884, 'BERT Recall': 0.879, 'BERT F1': 0.882}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(chime_dataset, model, client, zero_shot_instruct7b_closest, chime_generation_config, chime_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "moving-third",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 40 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 760\n",
      "sentence 1\n",
      "REF: at the close the financial times thirty share index was three point nine points lower at one thousand four hundred *** eighteen point   six\n",
      "HYP: at the close the financial times thirty share index was three point nine points lower at one thousand four hundred and eighteen point seven\n",
      "                                                                                                                          I                    S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 341\n",
      "sentence 1\n",
      "REF: economists were encouraged by a one point six percent increase in new orders for        non defense capital goods an important indicator of future business investment\n",
      "HYP: economists were encouraged by a one point six percent increase in new orders for nondefense ******* capital goods an important indicator of future business investment\n",
      "                                                                                               S       D                                                                   \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 622\n",
      "sentence 1\n",
      "REF: washington national paid nineteen dollars a share for the two point six million ** united ****** presidential shares it did not already own\n",
      "HYP: washington national paid nineteen ******* a share for the two point six million of united states      federal shares it *** *** already had\n",
      "                                             D                                        I             I            S             D   D           S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_chime4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.128, 'METEOR': 0.916, 'BERT Precision': 0.857, 'BERT Recall': 0.858, 'BERT F1': 0.857}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(chime_dataset, model, client, zero_shot_instruct7c, chime_generation_config, chime_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "precise-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 40 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1084\n",
      "sentence 1\n",
      "REF: grand auto ** slid three to fifteen and one eighth on the american stock exchange\n",
      "HYP: grand auto is lead three to fifteen and one  eight on the american stock exchange\n",
      "                 I    S                               S                               \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1197\n",
      "sentence 1\n",
      "REF: the market is strength may show that demand is not all a creation of incentives\n",
      "HYP: the market ** strength may show that demand is not all a creation of incentives\n",
      "                 D                                                                  \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1284\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_chime4.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.108, 'METEOR': 0.922, 'BERT Precision': 0.883, 'BERT Recall': 0.879, 'BERT F1': 0.881}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(chime_dataset, model, client, zero_shot_instruct7c_closest, chime_generation_config, chime_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "korean-possible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 211 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 65\n",
      "sentence 1\n",
      "REF: that are making really distinctive things\n",
      "HYP: that *** making really distinctive things\n",
      "            D                                 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1917\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1593\n",
      "sentence 1\n",
      "REF: *** to get down the canal ** **\n",
      "HYP: and to get down the canal it is\n",
      "       I                        I  I\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_lrs2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.13, 'METEOR': 0.899, 'BERT Precision': 0.881, 'BERT Recall': 0.86, 'BERT F1': 0.871}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(lrs_dataset, model, client, zero_shot_instruct7a, lrs_generation_config, lrs_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "driving-pipeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 211 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 2219\n",
      "sentence 1\n",
      "REF: *** it   is a bit of fun\n",
      "HYP: let us have a bit of fun\n",
      "       I  S    S             \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 257\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1076\n",
      "sentence 1\n",
      "REF: it is made us **** ** think out of the box\n",
      "HYP: it is made us sort of think out of the box\n",
      "                      I  I                     \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_lrs2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.123, 'METEOR': 0.902, 'BERT Precision': 0.887, 'BERT Recall': 0.864, 'BERT F1': 0.875}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(lrs_dataset, model, client, zero_shot_instruct7a_closest, lrs_generation_config, lrs_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "under-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 211 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1237\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 551\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 2121\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_lrs2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.133, 'METEOR': 0.897, 'BERT Precision': 0.881, 'BERT Recall': 0.86, 'BERT F1': 0.871}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(lrs_dataset, model, client, zero_shot_instruct7b, lrs_generation_config, lrs_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incorporated-behavior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 211 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 80\n",
      "sentence 1\n",
      "REF: *** they will ride up with wear *** **********\n",
      "HYP: and they will ride up with wear and everything\n",
      "       I                               I          I\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 181\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 39\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_lrs2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.125, 'METEOR': 0.902, 'BERT Precision': 0.886, 'BERT Recall': 0.862, 'BERT F1': 0.874}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(lrs_dataset, model, client, zero_shot_instruct7b_closest, lrs_generation_config, lrs_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "verbal-listening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 211 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 692\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1339\n",
      "sentence 1\n",
      "REF: there can be a diamond ring\n",
      "HYP:  that can be a diamond ring\n",
      "         S                      \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1183\n",
      "sentence 1\n",
      "REF: *** family came first\n",
      "HYP: and family came first\n",
      "       I                  \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_lrs2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.135, 'METEOR': 0.897, 'BERT Precision': 0.879, 'BERT Recall': 0.857, 'BERT F1': 0.868}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(lrs_dataset, model, client, zero_shot_instruct7c, lrs_generation_config, lrs_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "advised-genealogy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 211 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 361\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 787\n",
      "sentence 1\n",
      "REF: **** **** *** more of the light sensitive cells that work in low light levels ** ****\n",
      "HYP: they have got more of the light sensitive cells that work in low light levels as well\n",
      "        I    I   I                                                                  I    I\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 799\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_lrs2.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.125, 'METEOR': 0.901, 'BERT Precision': 0.885, 'BERT Recall': 0.862, 'BERT F1': 0.874}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(lrs_dataset, model, client, zero_shot_instruct7c_closest, lrs_generation_config, lrs_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-address",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "electronic-comfort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm an AI language model developed by OpenAI, here to assist you with information, answer your questions, and help with a variety of topics. Whether you need advice, explanations, or just a friendly chat, feel free to ask! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4o\"\n",
    "await check_availability(client, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aging-coffee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1047\n",
      "sentence 1\n",
      "REF:  moxi menu provides access to parental controls through the settings category\n",
      "HYP: moxie menu provides access to parental controls through the settings category\n",
      "         S                                                                        \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 902\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 563\n",
      "sentence 1\n",
      "REF: filezilla author tim kosse has been very reluctant to add encrypted storage\n",
      "HYP: filezilla author tim  cost has been very reluctant to add encrypted storage\n",
      "                              S                                                 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.137, 'METEOR': 0.883, 'BERT Precision': 0.812, 'BERT Recall': 0.828, 'BERT F1': 0.82}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct9, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-chart",
   "metadata": {},
   "source": [
    "## Playground of LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "departmental-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://kscope.vectorinstitute.ai/v1\"\n",
    "api_key = os.environ.get(\"CUSTOM_API_KEY\")\n",
    "client = openai.AsyncOpenAI(api_key=api_key, base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "artistic-ownership",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am Gemma, an open-weights AI assistant developed by the Gemma team at Google DeepMind. I'm a large language model, which means I'm trained on a massive amount of text data. This allows me to understand and generate human-like text, answer your questions, summarize information, write stories, and much more.\n",
      "\n",
      "As an open-weights model, my weights are publicly accessible. This means anyone can inspect, modify, or build upon me, fostering transparency and collaboration in the AI community.\n",
      "\n",
      "I'm still under development, but I'm learning new things every day. I'm excited to see how people use me to explore the possibilities of artificial intelligence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = \"gemma-2-9b-it\"\n",
    "await check_availability(client, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "apparent-entity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1763\n",
      "sentence 1\n",
      "REF: today   most     of   the noongar live in the perth metropolitan region\n",
      "HYP: today mister nungal lived ******* **** in the perth metropolitan region\n",
      "                S      S     S       D    D                                 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1784\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1569\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.144, 'METEOR': 0.883, 'BERT Precision': 0.812, 'BERT Recall': 0.827, 'BERT F1': 0.819}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct1, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pleased-royal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 985\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 761\n",
      "sentence 1\n",
      "REF: he exhibited a far going    syncretism\n",
      "HYP: he exhibited a far going synchronicity\n",
      "                                          S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 860\n",
      "sentence 1\n",
      "REF: the crater interior is relatively flat and marked only by tiny craterlets\n",
      "HYP: the crater interior is relatively flat and mocked only by tiny  quagilets\n",
      "                                                     S                       S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.138, 'METEOR': 0.881, 'BERT Precision': 0.809, 'BERT Recall': 0.822, 'BERT F1': 0.816}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct1_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efficient-training",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 980\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 16\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 387\n",
      "sentence 1\n",
      "REF: * modern monetary systems usually  consist of mints central banks and commercial banks\n",
      "HYP: a modern monetary  system usually consists of ***** central banks and commercial banks\n",
      "     I                       S                S        D                                   \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.162, 'METEOR': 0.875, 'BERT Precision': 0.808, 'BERT Recall': 0.824, 'BERT F1': 0.816}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct2, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spare-manual",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 534\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 986\n",
      "sentence 1\n",
      "REF: the work was left incomplete at the author is death\n",
      "HYP: the work was left incomplete at the author is  desk\n",
      "                                                       S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 861\n",
      "sentence 1\n",
      "REF: this layer is generally rich in nutrients  and weathers to form deep clay loams\n",
      "HYP: this layer is generally rich in nutrients that weathers to form deep clay loams\n",
      "                                                  S                                 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.137, 'METEOR': 0.882, 'BERT Precision': 0.811, 'BERT Recall': 0.824, 'BERT F1': 0.818}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct2_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "approximate-taxation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1879\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1312\n",
      "sentence 1\n",
      "REF: he was also known for his meticulous research behind the books\n",
      "HYP: he was also known for his meticulous research behind the  book\n",
      "                                                                  S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1830\n",
      "sentence 1\n",
      "REF: * young girl wearing * gray and pink sweater and leather boots shields her    face from the camera\n",
      "HYP: a young girl wearing a gray and pink sweater and leather boots shields the surface from the camera\n",
      "     I                    I                                                   S       S                \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.16, 'METEOR': 0.875, 'BERT Precision': 0.807, 'BERT Recall': 0.821, 'BERT F1': 0.814}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct3, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "verified-minimum",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1744\n",
      "sentence 1\n",
      "REF: oliver aide  to mister bogan who had ****** rubbermaid in his arms fainted\n",
      "HYP: oliver    i too mister bogan who had rubber       made in his arms fainted\n",
      "               S   S                           I          S                    \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1565\n",
      "sentence 1\n",
      "REF: this map shows   counties as well as ***** municipalities\n",
      "HYP: this map shows continuous as well as bonus         levels\n",
      "                             S                I              S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 952\n",
      "sentence 1\n",
      "REF: canadian explosives limited built an additional cordite factory at nobel ontario\n",
      "HYP: canadian explosives limited built an additional cordite factory at novel ontario\n",
      "                                                                            S        \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.139, 'METEOR': 0.881, 'BERT Precision': 0.81, 'BERT Recall': 0.823, 'BERT F1': 0.817}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct3_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "chubby-reservoir",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 910\n",
      "sentence 1\n",
      "REF: the single is b side was the         non album track elaine\n",
      "HYP: the single ** b site was the nonexistent track    of elaine\n",
      "                 D      S                   S     S     S       \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 659\n",
      "sentence 1\n",
      "REF: its main base is *** marshall islands international airport ** majuro\n",
      "HYP: its main base is the marshall islands international airport in majuro\n",
      "                        I                                         I       \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1884\n",
      "sentence 1\n",
      "REF: two fighters **** kickboxing\n",
      "HYP: two fighters king       foxy\n",
      "                     I          S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.16, 'METEOR': 0.875, 'BERT Precision': 0.807, 'BERT Recall': 0.822, 'BERT F1': 0.814}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct4, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "consistent-coverage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 495\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1054\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 98\n",
      "sentence 1\n",
      "REF: it was performed by bryan adams  rod stewart and sting\n",
      "HYP: ** was performed by brian adams rudd stewart and sting\n",
      "      D                      S          S                  \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.138, 'METEOR': 0.882, 'BERT Precision': 0.811, 'BERT Recall': 0.823, 'BERT F1': 0.817}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct4_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "regional-milan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1642\n",
      "sentence 1\n",
      "REF: he spent most of his life as a junior member of the ducal **** family\n",
      "HYP: he spent most of his life as a junior member of the ducal karl family\n",
      "                                                                  I       \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 770\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1826\n",
      "sentence 1\n",
      "REF: **** ** females and ** immatures have *** *** olive upperparts yellow ***** underparts and a gray head and neck\n",
      "HYP: like it females and in  pictures have all you upper      parts yellow under      parts and * gray head and neck\n",
      "        I  I              I         S        I   I     S          S            I          S     D                   \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.161, 'METEOR': 0.876, 'BERT Precision': 0.808, 'BERT Recall': 0.821, 'BERT F1': 0.814}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct5, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "supreme-honolulu",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1025\n",
      "sentence 1\n",
      "REF: the whole party stood like men stupefied\n",
      "HYP: the whole party stood like men stupified\n",
      "                                            S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 380\n",
      "sentence 1\n",
      "REF: they will keep for at least a week         if stored in an airtight container\n",
      "HYP: then **** keep for  a  late * week installing ****** ** an airtight container\n",
      "        S    D           S     S D               S      D  D                      \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 743\n",
      "sentence 1\n",
      "REF: the gold belt ** byway contains many roads\n",
      "HYP: the gold belt by   way contains many roads\n",
      "                    I     S                    \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.138, 'METEOR': 0.882, 'BERT Precision': 0.81, 'BERT Recall': 0.823, 'BERT F1': 0.816}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct5_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "violent-mercury",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 437\n",
      "sentence 1\n",
      "REF: she was a member of the bureau of the european  people is party\n",
      "HYP: she was a member of the bureau of the european peoples ** party\n",
      "                                                          S  D      \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 662\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 358\n",
      "sentence 1\n",
      "REF: in some cases the purpose of this operation    is to correct excessive vomiting\n",
      "HYP: in some cases the purpose of this operation needs to correct excessive vomiting\n",
      "                                                     S                              \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.154, 'METEOR': 0.877, 'BERT Precision': 0.81, 'BERT Recall': 0.824, 'BERT F1': 0.817}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct6, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "polyphonic-directory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 124\n",
      "sentence 1\n",
      "REF: it became a symbol of failed engineering and the dangers of arrogance in design\n",
      "HYP: it became a symbol of  field engineering and the dangers of arrogance in design\n",
      "                                S                                                   \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 223\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1198\n",
      "sentence 1\n",
      "REF: **** he returned to ***** cleveland and lived in a commune for the next several years\n",
      "HYP: here it     tend to cloud      land and lived in a commune for the next several  days\n",
      "        I  S        S        I         S                                                 S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.139, 'METEOR': 0.881, 'BERT Precision': 0.809, 'BERT Recall': 0.822, 'BERT F1': 0.816}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct6_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sudden-welding",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 852\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 89\n",
      "sentence 1\n",
      "REF: later platonists clarified that the eternal model existed in the mind of the demiurge\n",
      "HYP: later      plato clarified that the eternal model existed in the mind of the demiurge\n",
      "                    S                                                                     \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 770\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.146, 'METEOR': 0.881, 'BERT Precision': 0.807, 'BERT Recall': 0.825, 'BERT F1': 0.816}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mathematical-nomination",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1796\n",
      "sentence 1\n",
      "REF:   they were anti republican anti democratic and preached government on high by    a marked noble elite\n",
      "HYP: though   an anti republican anti democratic and   preach government on high by mark ****** noble elite\n",
      "          S    S                                            S                          S      D            \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1432\n",
      "sentence 1\n",
      "REF: an excellent tactical captain *** he  was warmhearted and devoted to the game\n",
      "HYP: an excellent tactical captain who is warm     hearted and devoted to the game\n",
      "                                     I  S    S           S                        \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 57\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.139, 'METEOR': 0.88, 'BERT Precision': 0.807, 'BERT Recall': 0.821, 'BERT F1': 0.814}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "underlying-start",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1322\n",
      "sentence 1\n",
      "REF:   ashoro also boasts many park golf courses that are available to all citizens\n",
      "HYP: ashwarro also boasts many park golf courses that are available to all citizens\n",
      "            S                                                                      \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1176\n",
      "sentence 1\n",
      "REF: it  stars    monty woolley roddy mcdowall and **** anne   baxter\n",
      "HYP: it starts mounting   wally  rodi   magdol and anni   in berkster\n",
      "             S        S       S     S        S        I    S        S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 679\n",
      "sentence 1\n",
      "REF: caplin cove also consists of many natural underground      fresh water springs\n",
      "HYP: kaplan cove also consists of many natural underground freshwater ***** springs\n",
      "          S                                                         S     D        \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.143, 'METEOR': 0.879, 'BERT Precision': 0.804, 'BERT Recall': 0.821, 'BERT F1': 0.813}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct8, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aware-inside",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1145\n",
      "sentence 1\n",
      "REF: this  cadre of educators went out into remote communities to teach rural blacks\n",
      "HYP:  the skater of educators went out into remote communities to teach rural blacks\n",
      "        S      S                                                                    \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1098\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 956\n",
      "sentence 1\n",
      "REF: most had been located by the men of station j\n",
      "HYP: most had been located by the men of station g\n",
      "                                                 S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.143, 'METEOR': 0.878, 'BERT Precision': 0.803, 'BERT Recall': 0.818, 'BERT F1': 0.81}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct8_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-story",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "worth-literature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 470\n",
      "sentence 1\n",
      "REF: in addition mccune has dedicated a dissertation on this topic\n",
      "HYP: in addition mcewen has dedicated a dissertation on this topic\n",
      "                      S                                           \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 283\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1627\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.143, 'METEOR': 0.882, 'BERT Precision': 0.807, 'BERT Recall': 0.825, 'BERT F1': 0.816}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7a, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "united-antibody",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 172\n",
      "sentence 1\n",
      "REF: in the end he  kills sergei vladimir a loyal umbrella executive\n",
      "HYP: in the end he killed sergey vladimir a loyal umbrella executive\n",
      "                        S      S                                    \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 582\n",
      "sentence 1\n",
      "REF: unlike semba kizomba music is characterized by a slower and usually very romantic rhythm\n",
      "HYP: unlike simba kizomba music is characterized by a slower and usually very romantic rhythm\n",
      "                S                                                                            \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 333\n",
      "sentence 1\n",
      "REF: they let the  building that became in this     time blowers inn\n",
      "HYP: they let the buildings that become in this timeover   scene ***\n",
      "                          S           S                S       S   D\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.14, 'METEOR': 0.88, 'BERT Precision': 0.806, 'BERT Recall': 0.82, 'BERT F1': 0.813}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7a_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "constitutional-glance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 947\n",
      "sentence 1\n",
      "REF: the world has changed  he said\n",
      "HYP: the world has changed you said\n",
      "                             S     \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 900\n",
      "sentence 1\n",
      "REF: the former   amboy school is adjacent to   roy is\n",
      "HYP: the former amboise school is adjacent to royes **\n",
      "                      S                           S  D\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1317\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.147, 'METEOR': 0.88, 'BERT Precision': 0.807, 'BERT Recall': 0.824, 'BERT F1': 0.815}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7b, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "seasonal-private",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 4\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 262\n",
      "sentence 1\n",
      "REF: he then traveled through italy and sicily     as tutor to baron krischer\n",
      "HYP: he then traveled through italy and sicily astute ***** to byron  crusher\n",
      "                                                    S     D        S        S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 446\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.14, 'METEOR': 0.88, 'BERT Precision': 0.807, 'BERT Recall': 0.821, 'BERT F1': 0.814}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7b_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "atlantic-knife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 458\n",
      "sentence 1\n",
      "REF: he was a founding member of saint  andrew is presbyterian church in ottawa\n",
      "HYP: he was a founding member of saint andrews ** presbyterian church in notava\n",
      "                                             S  D                             S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1328\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1050\n",
      "sentence 1\n",
      "REF: slater also serves on the corporate boards of delta      air lines and verizon\n",
      "HYP: slater also serves on the corporate boards of delta airlines ***** and verizon\n",
      "                                                                S     D            \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.144, 'METEOR': 0.881, 'BERT Precision': 0.806, 'BERT Recall': 0.824, 'BERT F1': 0.815}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7c, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "vulnerable-blake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 256 tests completed!\n",
      "Progress: Batch of 208 tests completed!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1988\n",
      "sentence 1\n",
      "REF: louise henriette *** accompanied her husband to the field despite being pregnant\n",
      "HYP:     we henriette are   convening her husband to the field despite being pregnant\n",
      "          S             I           S                                                \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 1493\n",
      "sentence 1\n",
      "REF: the first music director of the kitchen was composer  rhys chatham\n",
      "HYP: the first music director of the kitchen was composer rayse chattam\n",
      "                                                              S       S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sample 845\n",
      "sentence 1\n",
      "REF: the name may be attributed to a line in the isaac **** ** watts hymn alas\n",
      "HYP: the name may be attributed to a line in the isaac watt is  time   al ahaj\n",
      "                                                          I  I     S    S    S\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Results saved to /fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WER': 0.14, 'METEOR': 0.88, 'BERT Precision': 0.806, 'BERT Recall': 0.82, 'BERT F1': 0.813}\n"
     ]
    }
   ],
   "source": [
    "results_table = await evaluate_model_parallel(cv_dataset, model, client, zero_shot_instruct7c_closest, cv_generation_config, cv_results_path)\n",
    "print(results_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kscope",
   "language": "python",
   "name": "kscope"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
