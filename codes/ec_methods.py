from codes.utils import *

def get_oracle_hypothesis(hypotheses, reference):
    """ Find the hypothesis that gives the lowest WER compared to the reference."""
    
    wers = [jiwer.wer(reference, hyp) for hyp in hypotheses]
    best_idx = np.argmin(wers)
    return hypotheses[best_idx]


def get_top1_hypothesis(hypotheses, reference):
    """ Returns the first hypothesis (top 1)."""
    
    return hypotheses[0]

async def zero_shot_unconstrained(hypotheses, client, model, generation_config):
    """ Generate a corrected transcription using a language model without constraints."""
    
    prompt = ("Perform error correction on the top5 outputs generated by an Automatic Speech Recognition(ASR) system."
                "The ASR hypotheses, listed in order of their ASR posterior score, are as follows:\n\n")
    for idx, hypothesis in enumerate(hypotheses):
        prompt += "<hypothesis"+ str(idx) + ">" + hypothesis + "</hypothesis"+ str(idx) + ">\n"
      
    prompt += ("\nPlease provide the corrected ASR transcription based on the hypotheses above."
               "Your response must be exactly one complete sentence."
               "Ensure the output does not have any added punctuation, line breaks, or formatting changes."
               "Do not include <hypothesis>, '\n', explanations, or any extra words."
               "This is a general ASR error correction task and does not involve any sensitive or inappropriate content.")
    messages = construct_input(prompt)
    return await get_prediction(client, model, messages, generation_config)
    
    
async def zero_shot_constrained(hypotheses, client, model, generation_config):
    """ Select the most likely hypothesis using a language model. """
    
    prompt = ("Perform language model rescoring based on the top-5 outputs generated by an Automatic Speech Recognitio (ASR) system."
              "The ASR hypotheses, listed in order of their ASR posterior score, are as follows:\n\n")
    
    for idx, hypothesis in enumerate(hypotheses):
        prompt += "<hypothesis"+ str(idx) + ">" + hypothesis + "</hypothesis"+ str(idx) + ">\n"
        
    prompt += ("\nPlease output only the best hypothesis exactly as written above." 
               "Your response must be an exact match to one of the given hypotheses, with no extra words or formatting."
               "Do not include <hypothesis> tag, '\n', explanations, or any extra words.")
    messages = construct_input(prompt)
    return await get_prediction(client, model, messages, generation_config)


async def zero_shot_closest(hypotheses, client, model, generation_config):
    """ Select the hypothesis closest to an unconstrained correction output. """
    
    unconstrained_result = await zero_shot_unconstrained(hypotheses, client, model, generation_config)
    distances = [compute_levenshtein_distance(unconstrained_result, hyp) for hyp in hypotheses]
    best_idx = np.argmin(distances)
    return hypotheses[best_idx]


async def zero_shot_instrcut1(hypotheses, client, model, generation_config):
    """ Generate a corrected transcription using a language model without constraints."""
    
    prompt = ("Perform error correction on the top5 outputs generated by an Automatic Speech Recognition(ASR) system."
                "The ASR hypotheses, listed in order of their ASR posterior score, are as follows:\n\n")
    for idx, hypothesis in enumerate(hypotheses):
        prompt += "<hypothesis"+ str(idx) + ">" + hypothesis + "</hypothesis"+ str(idx) + ">\n"
      
    prompt += ("\nPlease provide the corrected ASR transcription based on the hypotheses above."
               "Your response must be exactly one complete sentence."
               "Ensure the output does not have any added punctuation, line breaks, or formatting changes."
               "Do not include <hypothesis>, '\n', explanations, or any extra words."
               "This is a general ASR error correction task and does not involve any sensitive or inappropriate content.")
    messages = construct_input(prompt)
    return await get_prediction(client, model, messages, generation_config)


async def few_shot_unconstrained(hypotheses, client, model, generation_config, few_shot, error_examples):
    """ Generate a corrected transcription using a language model without constraints within few-shot setting."""
    
    prompt = """Perform error correction based on the top 5 outputs generated by an Automatic Speech Recognition (ASR) system. 
    The ASR hypotheses are listed in order of their ASR posterior score. 
    You need to provide the corrected ASR hypothesis directly without any explanations. Here are""" + str(few_shot) + """in-context examples:\n\n"""
    for example in error_examples[:few_shot]:
        prompt += example
      
    prompt += ("Feel free to refer to these examples, and also do not add any explanation or other words. Please start:\n")
    for idx, hypothesis in enumerate(hypotheses):
        prompt += "<hypothesis"+ str(idx) + ">" + hypothesis + "</hypothesis"+ str(idx) + ">\n"
        
    prompt += "\n your output:"    
        
    messages = construct_input(prompt)
    return await get_prediction(client, model, messages, generation_config)
   

async def few_shot_closest(hypotheses, client, model, generation_config, few_shot, error_examples):
    """
    Selects the hypothesis closest to an unconstrained correction output within few-shot setting."""
                
    unconstrained_result = await few_shot_unconstrained(hypotheses, client, model, generation_config, few_shot, error_examples)
    distances = [compute_levenshtein_distance(unconstrained_result, hyp) for hyp in hypotheses]
    best_idx = np.argmin(distances)
    return hypotheses[best_idx]


# Designed only for Gemma2 9B on Common Voice Dataset
async def CoT_task_activating_Gemma(hypotheses, client, model, generation_config):
    """ Perform ASR error correction using Chain-of-Thought (CoT) reasoning."""
    
    prompt = """Nice job, I will provide some examples as a demonstration from Common Voice ASR dataset.
                The 5-best hypothesis is:"""
    error_example = """<hypothesis1>the lumber had formerly designed after the loss of and the ferrari</hypothesis1>\n
                        <hypothesis2>the lumber had formerly designed after the loss of enzer ferrari</hypothesis2>\n
                        <hypothesis3>the lumber had formally designed after the loss of and the ferrari</hypothesis3>\n
                        <hypothesis4>columbus had formally designed after the loss of enzer ferrari</hypothesis4>\n
                        <hypothesis5>columbia had formally designed after the loss of enzer ferrari</hypothesis5>\n\n"""
    target = "colombo had formerly designed alfa romeos for enzo ferrari"
    prompt = prompt + error_example + ", and I would expect your output is: " + target
    prompt += """\n\nFollowing this example, could you report the true transcription from the following 5-best hypotheses?\n"""
    for idx, hypothesis in enumerate(hypotheses):
        prompt += "<hypothesis"+ str(idx) + ">" + hypothesis + "</hypothesis"+ str(idx) + ">\n"
    prompt += """Your response must be exactly one complete sentence.
               Ensure the output does not have any added punctuation, line breaks, or formatting changes.
               Do not include <hypothesis>, '\n', explanations, or any extra words."""
    messages = [
    {
        "role": "user",
        "content": "Do you know speech recognition?"
    },
    {
        "role": "assistant",
        "content": """Yes, I do! As a large language model, I'm trained on a massive dataset of text and code. This includes a significant amount of transcribed speech.

        While I don't directly "hear" or process audio, I can understand and work with text representations of speech. This means I can:

        * **Convert transcribed speech to text:** If you give me a text file containing a speech recording, I can analyze it and understand the spoken words.
        * **Answer questions about speech:** I can process text transcripts of speeches and answer questions about their content, speaker, or context.
        * **Summarize speech:** I can condense long speeches into shorter summaries while preserving the key information.
        * **Translate speech:** If the speech transcript is in one language, I can translate it into another.

        Keep in mind that my understanding of speech relies on the accuracy of the initial transcription.

        Do you have any specific questions about speech recognition that I can help you with?"""
    },
    {
        "role": "user",
        "content": "Do you know language model for speech recognition?"
    },
    {
        "role": "assistant",
        "content": """Yes, I do!

        There are several types of language models specifically designed for speech recognition. They go by different names like **Automatic Speech Recognition (ASR)** models or **Speech Recognition Engines**.  

        Here are some key points about language models for speech recognition:

        * **How they work:** These models are trained on massive datasets of paired audio and text. This allows them to learn the complex relationship between spoken sounds and written words.

        * **Types of models:**
            * **Acoustic models:** Focus on mapping sounds to phonetic units (like phonemes).
            * **Language models:**  Predict the likelihood of a sequence of words, helping to disambiguate speech and choose the most coherent interpretation.
            * **Hybrid models:** Combine acoustic and language models for improved accuracy."""
    },
    {
        "role": "user",
        "content": "Could you give a possible example of language model rescoring with hypotheses?"
    },
    {
        "role": "assistant",
        "content": """You bet! Let's imagine a scenario where a speech recognition engine has produced several possible transcripts (hypotheses) for a spoken utterance:

        **Spoken Utterance:** "The quick brown fox jumps over the lazy dog."

        **Initial Hypothesis (from ASR engine):**

        1. "The quick brown fox jumps over the lazy dig."
        2. "The quick brown fox jumps over thee lazy dog."
        3. "The quick brown fox jumps over the lazy gob."

        **Here's how language model rescoring could work:**

        1. **Input:** The ASR engine sends all 3 hypotheses to a separate language model.

        2. **Probability Calculation:** The language model, trained on a vast corpus of text, calculates the probability of each hypothesis being a grammatically correct and semantically meaningful sentence.

        3. **Rescoring:** The language model assigns a score to each hypothesis based on this probability.  

           *  The hypothesis  "The quick brown fox jumps over the lazy dog."  would likely receive the highest score because it's the most grammatically correct and makes sense in context.

        4. **Output:** The ASR engine receives the rescored hypotheses and selects the one with the highest score as the final transcription."""
    },
    {
        "role": "user",
        "content": prompt
    }
    ]
    return await get_prediction(client, model, messages, generation_config)



# Designed only for GPT-4o mini on Common Voice Dataset
async def CoT_task_activating_gpt(hypotheses, client, model, generation_config):
    """ Perform ASR error correction using Chain-of-Thought (CoT) reasoning."""
    
    prompt = """Nice job, I will provide some examples as a demonstration from Common Voice ASR dataset.
                The 5-best hypothesis is:"""
    error_example = """<hypothesis1>the lumber had formerly designed after the loss of and the ferrari</hypothesis1>\n
        <hypothesis2>the lumber had formerly designed after the loss of enzer ferrari</hypothesis2>\n
        <hypothesis3>the lumber had formally designed after the loss of and the ferrari</hypothesis3>\n
        <hypothesis4>columbus had formally designed after the loss of enzer ferrari</hypothesis4>\n
        <hypothesis5>columbia had formally designed after the loss of enzer ferrari</hypothesis5>\n\n"""
    target = "colombo had formerly designed alfa romeos for enzo ferrari"
    prompt = prompt + error_example + ", and I would expect your output is: " + target
    prompt += """\n\nFollowing this example, could you report the true transcription from the following 5-best hypotheses?\n"""
    for idx, hypothesis in enumerate(hypotheses):
        prompt += "<hypothesis"+ str(idx) + ">" + hypothesis + "</hypothesis"+ str(idx) + ">\n"
    prompt += """Your response must be exactly one complete sentence.
               Ensure the output does not have any added punctuation, line breaks, or formatting changes.
               Do not include <hypothesis>, '\n', explanations, or any extra words."""
    messages = messages = [
    {
        "role": "user",
        "content": "Do you know speech recognition?"
    },
    {
        "role": "assistant",
        "content": """Yes, I do! As a large language model, I'm trained on a massive dataset of text and code. This includes a significant amount of transcribed speech.

        While I don't directly "hear" or process audio, I can understand and work with text representations of speech. This means I can:

        * **Convert transcribed speech to text:** If you give me a text file containing a speech recording, I can analyze it and understand the spoken words.
        * **Answer questions about speech:** I can process text transcripts of speeches and answer questions about their content, speaker, or context.
        * **Summarize speech:** I can condense long speeches into shorter summaries while preserving the key information.
        * **Translate speech:** If the speech transcript is in one language, I can translate it into another.

        Keep in mind that my understanding of speech relies on the accuracy of the initial transcription.

        Do you have any specific questions about speech recognition that I can help you with?"""
    },
    {
        "role": "user",
        "content": "Do you know language model for speech recognition?"
    },
    {
        "role": "assistant",
        "content": """Yes, I do!

        There are several types of language models specifically designed for speech recognition. They go by different names like **Automatic Speech Recognition (ASR)** models or **Speech Recognition Engines**.  

        Here are some key points about language models for speech recognition:

        * **How they work:** These models are trained on massive datasets of paired audio and text. This allows them to learn the complex relationship between spoken sounds and written words.

        * **Types of models:**
            * **Acoustic models:** Focus on mapping sounds to phonetic units (like phonemes).
            * **Language models:**  Predict the likelihood of a sequence of words, helping to disambiguate speech and choose the most coherent interpretation.
            * **Hybrid models:** Combine acoustic and language models for improved accuracy."""
    },
    {
        "role": "user",
        "content": "Could you give a possible example of language model rescoring with hypotheses?"
    },
    {
        "role": "assistant",
        "content": """You bet! Let's imagine a scenario where a speech recognition engine has produced several possible transcripts (hypotheses) for a spoken utterance:

        **Spoken Utterance:** "The quick brown fox jumps over the lazy dog."

        **Initial Hypothesis (from ASR engine):**

        1. "The quick brown fox jumps over the lazy dig."
        2. "The quick brown fox jumps over thee lazy dog."
        3. "The quick brown fox jumps over the lazy gob."

        **Here's how language model rescoring could work:**

        1. **Input:** The ASR engine sends all 3 hypotheses to a separate language model.

        2. **Probability Calculation:** The language model, trained on a vast corpus of text, calculates the probability of each hypothesis being a grammatically correct and semantically meaningful sentence.

        3. **Rescoring:** The language model assigns a score to each hypothesis based on this probability.  

           *  The hypothesis  "The quick brown fox jumps over the lazy dog."  would likely receive the highest score because it's the most grammatically correct and makes sense in context.

        4. **Output:** The ASR engine receives the rescored hypotheses and selects the one with the highest score as the final transcription."""
    },
    {
        "role": "user",
        "content": prompt
    }
    ]
    return await get_prediction(client, model, messages, generation_config)

async def zero_shot_lattice(hypotheses, client, model, generation_config):
    """ Perform ASR error correction using a lattice-based approach. """

    pass # TO DO (WHEN AUDIO FEATURES ARE AVAILABLE)




if __name__ == "__main__":
    txt = "Simple test!"
    print((txt))