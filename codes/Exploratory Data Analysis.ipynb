{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pharmaceutical-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-trinidad",
   "metadata": {},
   "source": [
    "## Common Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ranging-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/fs01/home/omidv/ASR-Error-Correction/results/test_cv.json\")\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "continuing-journalism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1\n",
      "REF: it  stars    monty woolley roddy mcdowall and **** anne   baxter\n",
      "HYP: it starts mounting   wally  rodi  mengdol and anni   in berkster\n",
      "             S        S       S     S        S        I    S        S\n",
      "\n",
      "sentence 2\n",
      "REF: *** colombo had formerly designed ***** *** alfa romeos for enzo ferrari\n",
      "HYP: the  lumber had formerly designed after the loss     of and  the ferrari\n",
      "       I       S                           I   I    S      S   S    S        \n",
      "\n",
      "sentence 3\n",
      "REF: miles  is  an  alumnus     of seton      hall university\n",
      "HYP:     i see the luminous offset    on hollywood university\n",
      "         S   S   S        S      S     S         S           \n",
      "\n",
      "sentence 4\n",
      "REF: the ****** * ****** skjervefossen waterfall is also located in  granvin\n",
      "HYP: the shisha v falson           war      four is also located at grandven\n",
      "              I I      I             S         S                  S        S\n",
      "\n",
      "sentence 5\n",
      "REF: the committee and ****** **** unsworth supported the sale\n",
      "HYP: the   comment and answer with  support        is the same\n",
      "                 S          I    I        S         S        S\n",
      "\n",
      "sentence 6\n",
      "REF: he ****** attended beal high school ***  in ilford\n",
      "HYP: he tended       to view high school and ill    fed\n",
      "             I        S    S               I   S      S\n",
      "\n",
      "sentence 7\n",
      "REF: ***** hedenbergite is almost never found ** ****** isolated\n",
      "HYP: didan      burjite is almost never found or should       it\n",
      "         I            S                        I      I        S\n",
      "\n",
      "sentence 8\n",
      "REF: see * fish anatomy for **** ** fin descriptions\n",
      "HYP: see a fish anatomy for free in the  description\n",
      "         I                     I  I   S            S\n",
      "\n",
      "sentence 9\n",
      "REF: *** **** **** ** sarehole mill produces wholemeal flour which is sold in the mill shop\n",
      "HYP: the sear hole we  produce   is     gold      leaf north which is sold in the mule shop\n",
      "       I    I    I  I        S    S        S         S     S                         S     \n",
      "\n",
      "sentence 10\n",
      "REF: queen   elena granted ******* anatoly durov  jun\n",
      "HYP: queen eleanor granted anatoli    duro    of june\n",
      "                 S               I       S     S    S\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"output\"] = df[\"output\"].apply(preprocess)\n",
    "df[\"input1\"] = df[\"input1\"].apply(preprocess)\n",
    "df[\"WER\"] = df.apply(lambda row: compute_wer(row[\"output\"], row[\"input1\"]), axis=1)\n",
    "worst_cases = df.sort_values(by=\"WER\", ascending=False)\n",
    "worst_cases = worst_cases.head(10)\n",
    "pred = list(worst_cases[\"input1\"].values)\n",
    "pred = [clean_asr_output(remove_punctuation(ref.lower())) for ref in pred]\n",
    "target = list(worst_cases[\"output\"].values)\n",
    "report = jiwer.process_words(target, pred)\n",
    "print(jiwer.visualize_alignment(report, show_measures=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aerial-artist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUBSTITUTIONS ===\n",
      "a         --> the       = 20x\n",
      "the       --> a         = 10x\n",
      "their     --> the       = 7x\n",
      "this      --> the       = 5x\n",
      "the       --> this      = 5x\n",
      "its       --> is        = 5x\n",
      "and       --> in        = 4x\n",
      "his       --> this      = 4x\n",
      "he        --> here      = 3x\n",
      "or        --> of        = 3x\n",
      "he        --> you       = 3x\n",
      "the       --> to        = 2x\n",
      "bryan     --> brian     = 2x\n",
      "their     --> there     = 2x\n",
      "doon      --> dune      = 2x\n",
      "completed --> complete  = 2x\n",
      "their     --> are       = 2x\n",
      "its       --> it        = 2x\n",
      "a         --> our       = 2x\n",
      "an asian  --> a nation  = 2x\n",
      "\n",
      "=== INSERTIONS ===\n",
      "the   = 32x\n",
      "a     = 11x\n",
      "to    = 10x\n",
      "it    = 8x\n",
      "and   = 6x\n",
      "in    = 5x\n",
      "for   = 5x\n",
      "is    = 5x\n",
      "will  = 5x\n",
      "new   = 4x\n",
      "north = 4x\n",
      "of    = 3x\n",
      "they  = 3x\n",
      "but   = 3x\n",
      "co    = 3x\n",
      "under = 3x\n",
      "south = 2x\n",
      "on    = 2x\n",
      "here  = 2x\n",
      "just  = 2x\n",
      "\n",
      "=== DELETIONS ===\n",
      "is        = 31x\n",
      "the       = 17x\n",
      "a         = 16x\n",
      "in        = 4x\n",
      "an        = 4x\n",
      "it        = 2x\n",
      "wrote     = 2x\n",
      "of        = 2x\n",
      "west      = 2x\n",
      "to        = 2x\n",
      "d         = 2x\n",
      "are       = 2x\n",
      "fifth     = 2x\n",
      "s         = 2x\n",
      "and       = 2x\n",
      "operation = 2x\n",
      "manors    = 1x\n",
      "denton    = 1x\n",
      "graham    = 1x\n",
      "vassals   = 1x\n"
     ]
    }
   ],
   "source": [
    "pred = [clean_asr_output(remove_punctuation(utter.lower())) for utter in dataset['input1']]\n",
    "target = [clean_asr_output(remove_punctuation(utter.lower())) for utter in dataset['output']]\n",
    "out = jiwer.process_words(target, pred)\n",
    "print(visualize_error_counts(out, top_k=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-television",
   "metadata": {},
   "source": [
    "## LRS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "assisted-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/fs01/home/omidv/ASR-Error-Correction/results/test_lrs2.json\")\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expensive-feedback",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1\n",
      "REF: *** ****** ******* *** ** ******* so we are going to start on that next week\n",
      "HYP: you bought another one at auction so we can ***** ** start on that next week\n",
      "       I      I       I   I  I       I         S     D  D                        \n",
      "\n",
      "sentence 2\n",
      "REF: you ***** were    a soldier    far from  home\n",
      "HYP: you would have sold    your father from homes\n",
      "             I    S    S       S      S          S\n",
      "\n",
      "sentence 3\n",
      "REF: ** so overall you  are minus five\n",
      "HYP: it is    over all your minus five\n",
      "      I  S       S   S    S           \n",
      "\n",
      "sentence 4\n",
      "REF: **** what else could i say\n",
      "HYP: well   it   is  good i say\n",
      "        I    S    S     S      \n",
      "\n",
      "sentence 5\n",
      "REF: you  mean  i   am   older\n",
      "HYP: you would be like boulder\n",
      "             S  S    S       S\n",
      "\n",
      "sentence 6\n",
      "REF: ** if  you fall in love\n",
      "HYP: it is your full in love\n",
      "      I  S    S    S        \n",
      "\n",
      "sentence 7\n",
      "REF:  and those are the ones\n",
      "HYP: that    is *** the  one\n",
      "        S     S   D        S\n",
      "\n",
      "sentence 8\n",
      "REF: it is a priceless  artifact\n",
      "HYP: to ** * priceless artifacts\n",
      "      S  D D                   S\n",
      "\n",
      "sentence 9\n",
      "REF: there was a *** dragon\n",
      "HYP:  that was a dry    gun\n",
      "         S         I      S\n",
      "\n",
      "sentence 10\n",
      "REF: *** they love  a death\n",
      "HYP: and they love it  that\n",
      "       I            S     S\n",
      "\n",
      "sentence 11\n",
      "REF: i believe in *** **** music ***\n",
      "HYP: i believe in you know music and\n",
      "                    I    I         I\n",
      "\n",
      "sentence 12\n",
      "REF: **** warms you right up\n",
      "HYP: will   not you  ride up\n",
      "        I     S         S   \n",
      "\n",
      "sentence 13\n",
      "REF:  they are the poor\n",
      "HYP: there *** the pool\n",
      "         S   D        S\n",
      "\n",
      "sentence 14\n",
      "REF: someone       nine to five\n",
      "HYP: someone ninetyfive ** ****\n",
      "                      S  D    D\n",
      "\n",
      "sentence 15\n",
      "REF: charlotte rhead studio ***** pottery\n",
      "HYP: charlotte  reed studio potry  itself\n",
      "                   S            I       S\n",
      "\n",
      "sentence 16\n",
      "REF: *** *** gardner found himself here\n",
      "HYP: god and       i found himself here\n",
      "       I   I       S                   \n",
      "\n",
      "sentence 17\n",
      "REF: talk quietly     to them\n",
      "HYP: talk   quite little ****\n",
      "                S      S    D\n",
      "\n",
      "sentence 18\n",
      "REF: the  isle    of wight\n",
      "HYP: the olive white    to\n",
      "             S     S     S\n",
      "\n",
      "sentence 19\n",
      "REF: *** earlier in the year\n",
      "HYP: you     are in the  air\n",
      "       I       S           S\n",
      "\n",
      "sentence 20\n",
      "REF: ** were shut up forever\n",
      "HYP: we  are shot up forever\n",
      "      I    S    S           \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[\"output\"] = df[\"output\"].apply(preprocess)\n",
    "df[\"input1\"] = df[\"input1\"].apply(preprocess)\n",
    "df[\"WER\"] = df.apply(lambda row: compute_wer(row[\"output\"], row[\"input1\"]), axis=1)\n",
    "worst_cases = df.sort_values(by=\"WER\", ascending=False)\n",
    "worst_cases = worst_cases.head(20)\n",
    "pred = list(worst_cases[\"input1\"].values)\n",
    "pred = [clean_asr_output(remove_punctuation(ref.lower())) for ref in pred]\n",
    "target = list(worst_cases[\"output\"].values)\n",
    "report = jiwer.process_words(target, pred)\n",
    "print(jiwer.visualize_alignment(report, show_measures=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "collect-mattress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUBSTITUTIONS ===\n",
      "cos      --> because  = 10x\n",
      "a        --> the      = 8x\n",
      "the      --> a        = 8x\n",
      "was      --> is       = 6x\n",
      "zero     --> thousand = 5x\n",
      "the      --> that     = 4x\n",
      "it       --> that     = 4x\n",
      "had      --> have     = 3x\n",
      "round    --> around   = 3x\n",
      "there    --> that     = 3x\n",
      "were     --> are      = 2x\n",
      "and      --> or       = 2x\n",
      "it       --> this     = 2x\n",
      "say      --> see      = 2x\n",
      "has      --> is       = 2x\n",
      "under    --> to       = 2x\n",
      "he       --> it       = 2x\n",
      "triumph  --> triumphs = 2x\n",
      "in       --> and      = 2x\n",
      "her      --> us       = 2x\n",
      "\n",
      "=== INSERTIONS ===\n",
      "and      = 93x\n",
      "so       = 26x\n",
      "that     = 24x\n",
      "but      = 20x\n",
      "the      = 19x\n",
      "now      = 19x\n",
      "well     = 18x\n",
      "a        = 14x\n",
      "it       = 13x\n",
      "because  = 12x\n",
      "in       = 10x\n",
      "thousand = 10x\n",
      "to       = 10x\n",
      "you know = 10x\n",
      "have     = 9x\n",
      "i        = 9x\n",
      "as well  = 8x\n",
      "of       = 8x\n",
      "very     = 8x\n",
      "for      = 8x\n",
      "\n",
      "=== DELETIONS ===\n",
      "is         = 9x\n",
      "it         = 7x\n",
      "and        = 6x\n",
      "are        = 5x\n",
      "to         = 5x\n",
      "of         = 4x\n",
      "have       = 4x\n",
      "so         = 3x\n",
      "on         = 3x\n",
      "that       = 3x\n",
      "but        = 3x\n",
      "would      = 3x\n",
      "a          = 3x\n",
      "you        = 3x\n",
      "at         = 2x\n",
      "i          = 2x\n",
      "lights     = 1x\n",
      "and twelve = 1x\n",
      "going to   = 1x\n",
      "work       = 1x\n"
     ]
    }
   ],
   "source": [
    "pred = [clean_asr_output(remove_punctuation(utter.lower())) for utter in dataset['input1']]\n",
    "target = [clean_asr_output(remove_punctuation(utter.lower())) for utter in dataset['output']]\n",
    "out = jiwer.process_words(target, pred)\n",
    "print(visualize_error_counts(out, top_k=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-professional",
   "metadata": {},
   "source": [
    "## Chime4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "editorial-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/fs01/home/omidv/ASR-Error-Correction/results/test_chime4.json\")\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "municipal-flower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUBSTITUTIONS ===\n",
      "nineteen eighty seven   --> hundred and eightyseven = 20x\n",
      "a                       --> the                     = 18x\n",
      "adviser                 --> advisor                 = 16x\n",
      "m                       --> micc                    = 15x\n",
      "seventy                 --> seventythree            = 12x\n",
      "twenty five             --> and twentyfive          = 12x\n",
      "forty                   --> fortyfive               = 10x\n",
      "m                       --> mci                     = 10x\n",
      "nineteen eighty six     --> hundred and eightysix   = 9x\n",
      "t                       --> twa                     = 9x\n",
      "\n",
      "=== INSERTIONS ===\n",
      "and                       = 130x\n",
      "one thousand nine         = 51x\n",
      "the                       = 19x\n",
      "one thousand nine hundred = 8x\n",
      "of                        = 8x\n",
      "on                        = 6x\n",
      "elder                     = 4x\n",
      "pre                       = 4x\n",
      "to                        = 4x\n",
      "hundred and sixtynine     = 4x\n",
      "\n",
      "=== DELETIONS ===\n",
      "dollars = 121x\n",
      "six     = 22x\n",
      "is      = 18x\n",
      "two     = 16x\n",
      "and     = 16x\n",
      "i c c   = 15x\n",
      "one     = 15x\n",
      "three   = 14x\n",
      "five    = 13x\n",
      "c i     = 12x\n"
     ]
    }
   ],
   "source": [
    "pred = [clean_asr_output(remove_punctuation(utter.lower())) for utter in dataset['input1']]\n",
    "target = [clean_asr_output(remove_punctuation(utter.lower())) for utter in dataset['output']]\n",
    "out = jiwer.process_words(target, pred)\n",
    "print(visualize_error_counts(out, top_k=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-pennsylvania",
   "metadata": {},
   "source": [
    "## Other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "portuguese-catering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUBSTITUTIONS ===\n",
      "a         --> the       = 13x\n",
      "brahman   --> brahmin   = 13x\n",
      "the       --> a         = 10x\n",
      "murdoch   --> murdock   = 9x\n",
      "hermon    --> hermann   = 8x\n",
      "dickie    --> dicky     = 7x\n",
      "cinderlad --> lad       = 7x\n",
      "an        --> and       = 6x\n",
      "anyone    --> one       = 6x\n",
      "their     --> the       = 5x\n",
      "\n",
      "=== INSERTIONS ===\n",
      "the  = 10x\n",
      "a    = 9x\n",
      "any  = 8x\n",
      "i    = 6x\n",
      "and  = 5x\n",
      "to   = 4x\n",
      "it   = 4x\n",
      "of   = 4x\n",
      "they = 3x\n",
      "in   = 3x\n",
      "\n",
      "=== DELETIONS ===\n",
      "and  = 7x\n",
      "of   = 7x\n",
      "a    = 5x\n",
      "the  = 5x\n",
      "it   = 4x\n",
      "boy  = 3x\n",
      "m    = 3x\n",
      "is   = 3x\n",
      "that = 3x\n",
      "am   = 3x\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"/fs01/home/omidv/ASR-Error-Correction/results/test_ls_other.json\")\n",
    "dataset = Dataset.from_pandas(df)\n",
    "pred = [clean_asr_output(remove_punctuation(utter[0].lower())) for utter in dataset['input']]\n",
    "target = [clean_asr_output(remove_punctuation(utter.lower())) for utter in dataset['output']]\n",
    "out = jiwer.process_words(target, pred)\n",
    "print(visualize_error_counts(out, top_k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accurate-patent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUBSTITUTIONS ===\n",
      "d       --> dc      = 35x\n",
      "nonstop --> stop    = 19x\n",
      "fare    --> fair    = 13x\n",
      "u       --> us      = 10x\n",
      "first   --> onest   = 7x\n",
      "a       --> to      = 7x\n",
      "t       --> twa     = 7x\n",
      "j       --> jfk     = 6x\n",
      "p       --> pm      = 6x\n",
      "fares   --> fairs   = 6x\n",
      "\n",
      "=== INSERTIONS ===\n",
      "non               = 19x\n",
      "hundred           = 12x\n",
      "point             = 3x\n",
      "new               = 3x\n",
      "hundred and       = 3x\n",
      "twentyeightth one = 2x\n",
      "one thousand      = 2x\n",
      "for               = 2x\n",
      "bye               = 1x\n",
      "it                = 1x\n",
      "\n",
      "=== DELETIONS ===\n",
      "c       = 35x\n",
      "p m     = 19x\n",
      "s       = 11x\n",
      "m       = 11x\n",
      "flights = 7x\n",
      "a       = 7x\n",
      "a m     = 7x\n",
      "w a     = 6x\n",
      "f k     = 6x\n",
      "seventh = 4x\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"/fs01/home/omidv/ASR-Error-Correction/results/test_atis.json\")\n",
    "dataset = Dataset.from_pandas(df)\n",
    "pred = [clean_asr_output(remove_punctuation(utter[0].lower())) for utter in dataset['input']]\n",
    "target = [clean_asr_output(remove_punctuation(utter.lower())) for utter in dataset['output']]\n",
    "out = jiwer.process_words(target, pred)\n",
    "print(visualize_error_counts(out, top_k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "otherwise-philosophy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUBSTITUTIONS ===\n",
      "they --> i    = 14x\n",
      "that --> it   = 13x\n",
      "in   --> and  = 13x\n",
      "the  --> a    = 11x\n",
      "and  --> in   = 11x\n",
      "a    --> the  = 8x\n",
      "t    --> tv   = 7x\n",
      "them --> him  = 7x\n",
      "were --> are  = 6x\n",
      "you  --> yeah = 6x\n",
      "\n",
      "=== INSERTIONS ===\n",
      "and  = 33x\n",
      "it   = 27x\n",
      "a    = 27x\n",
      "that = 20x\n",
      "the  = 16x\n",
      "i    = 15x\n",
      "have = 12x\n",
      "yeah = 11x\n",
      "you  = 10x\n",
      "is   = 9x\n",
      "\n",
      "=== DELETIONS ===\n",
      "i        = 131x\n",
      "and      = 118x\n",
      "you know = 64x\n",
      "the      = 54x\n",
      "it       = 50x\n",
      "a        = 48x\n",
      "that     = 41x\n",
      "it is    = 34x\n",
      "so       = 26x\n",
      "but      = 26x\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"/fs01/home/omidv/ASR-Error-Correction/results/test_swbd.json\")\n",
    "dataset = Dataset.from_pandas(df)\n",
    "pred = [clean_asr_output(remove_punctuation(utter[0].lower())) for utter in dataset['input']]\n",
    "target = [clean_asr_output(remove_punctuation(utter.lower())) for utter in dataset['output']]\n",
    "out = jiwer.process_words(target, pred)\n",
    "print(visualize_error_counts(out, top_k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "minus-reception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUBSTITUTIONS ===\n",
      "co        --> cotwo     = 15x\n",
      "could     --> can       = 7x\n",
      "this      --> the       = 6x\n",
      "a         --> the       = 5x\n",
      "ok        --> okay      = 5x\n",
      "the       --> a         = 5x\n",
      "twenty    --> twentyone = 5x\n",
      "and       --> in        = 4x\n",
      "a         --> one       = 4x\n",
      "and       --> now       = 3x\n",
      "\n",
      "=== INSERTIONS ===\n",
      "and                       = 16x\n",
      "a                         = 11x\n",
      "that                      = 8x\n",
      "it                        = 7x\n",
      "one thousand nine hundred = 5x\n",
      "but                       = 5x\n",
      "of                        = 4x\n",
      "so                        = 3x\n",
      "one thousand nine         = 3x\n",
      "you know                  = 3x\n",
      "\n",
      "=== DELETIONS ===\n",
      "and      = 47x\n",
      "the      = 25x\n",
      "i        = 18x\n",
      "two      = 18x\n",
      "a        = 17x\n",
      "you know = 11x\n",
      "is       = 10x\n",
      "that     = 10x\n",
      "now      = 8x\n",
      "to       = 8x\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"/fs01/home/omidv/ASR-Error-Correction/results/test_td3.json\")\n",
    "dataset = Dataset.from_pandas(df)\n",
    "pred = [clean_asr_output(remove_punctuation(utter[0].lower())) for utter in dataset['input']]\n",
    "target = [clean_asr_output(remove_punctuation(utter.lower())) for utter in dataset['output']]\n",
    "out = jiwer.process_words(target, pred)\n",
    "print(visualize_error_counts(out, top_k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "modular-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUBSTITUTIONS ===\n",
      "u                     --> us                    = 8x\n",
      "nineteen eighty six   --> hundred and eightysix = 6x\n",
      "seventy               --> seventyfive           = 5x\n",
      "incorporated          --> inc                   = 5x\n",
      "barry                 --> berry                 = 4x\n",
      "eighths               --> eight                 = 4x\n",
      "u                     --> un                    = 3x\n",
      "cease                 --> ceasefire             = 3x\n",
      "up                    --> upfront               = 3x\n",
      "i                     --> ibm                   = 3x\n",
      "\n",
      "=== INSERTIONS ===\n",
      "one thousand nine         = 17x\n",
      "one                       = 5x\n",
      "zero                      = 4x\n",
      "hundred                   = 3x\n",
      "and                       = 3x\n",
      "end                       = 2x\n",
      "one thousand nine hundred = 2x\n",
      "hundred and eightynine    = 2x\n",
      "a                         = 2x\n",
      "if                        = 1x\n",
      "\n",
      "=== DELETIONS ===\n",
      "dollars = 35x\n",
      "five    = 11x\n",
      "and     = 9x\n",
      "is      = 8x\n",
      "s       = 8x\n",
      "six     = 6x\n",
      "fire    = 4x\n",
      "four    = 4x\n",
      "dollar  = 4x\n",
      "n       = 3x\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"/fs01/home/omidv/ASR-Error-Correction/results/test_wsj_score.json\")\n",
    "dataset = Dataset.from_pandas(df)\n",
    "pred = [clean_asr_output(remove_punctuation(utter[0].lower())) for utter in dataset['input']]\n",
    "target = [clean_asr_output(remove_punctuation(utter.lower())) for utter in dataset['output']]\n",
    "out = jiwer.process_words(target, pred)\n",
    "print(visualize_error_counts(out, top_k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-environment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-labor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kscope",
   "language": "python",
   "name": "kscope"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
